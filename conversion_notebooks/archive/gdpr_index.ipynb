{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD vresion, needs updating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "processed_regs_file = \"./regs/gdpr.csv\"\n",
    "df = pd.read_csv(processed_regs_file, sep=\"|\", encoding=\"utf-8\", na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m openai_client \u001b[38;5;241m=\u001b[39m OpenAI(api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m),)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalid_index\u001b[39;00m\n\u001b[0;32m      6\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(src\u001b[38;5;241m.\u001b[39mvalid_index)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalid_index\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_gdpr_index, ValidIndex\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "openai_client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"),)\n",
    "\n",
    "import importlib\n",
    "import src.valid_index\n",
    "importlib.reload(src.valid_index)\n",
    "from src.valid_index import get_gdpr_index, ValidIndex\n",
    "\n",
    "reference_checker = get_gdpr_index()\n",
    "\n",
    "import src.embeddings\n",
    "importlib.reload(src.embeddings)\n",
    "from src.embeddings import num_tokens_from_string, get_ada_embedding\n",
    "\n",
    "import src.file_tools\n",
    "importlib.reload(src.file_tools)\n",
    "from src.file_tools import get_regulation\n",
    "\n",
    "import src.summarise_and_question\n",
    "importlib.reload(src.summarise_and_question)\n",
    "from src.summarise_and_question import get_summary_and_questions_for\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the current split of the tree so you can continue generating summaries and questions\n",
      "Total number of sections: 99\n"
     ]
    }
   ],
   "source": [
    "first_time = False\n",
    "#sectioned_df = pd.DataFrame([],columns = [\"article\", \"text\", \"token_count\"])\n",
    "save_sectioned_df_to_file = \"./tmp/manual.csv\"\n",
    "\n",
    "\n",
    "if first_time:\n",
    "    print(\"Loading the initial split of the tree. You will need to make changes to this as you see the data\")\n",
    "    sections_as_list = []\n",
    "    counter = 1    \n",
    "    unique_article_numbers = df[\"article_number\"].unique()\n",
    "    for article in unique_article_numbers:\n",
    "        if article != counter:\n",
    "            print(f\"Article {article} should be number {counter}\")\n",
    "            break\n",
    "        regs = get_regulation(df = df, index = str(article), reference_checker = index_checker, include_section_and_chapter=False)\n",
    "        num_tokens = num_tokens_from_string(regs)\n",
    "        sections_as_list.append([article, regs, num_tokens])\n",
    "        counter += 1\n",
    "\n",
    "    sectioned_df = pd.DataFrame(sections_as_list, columns = [\"article\", \"text\", \"token_count\"])\n",
    "    sectioned_df.to_csv(save_sectioned_df_to_file, encoding=\"utf-8\", sep=\"|\", index = False)\n",
    "else:\n",
    "    print(\"Loading the current split of the tree so you can continue generating summaries and questions\")\n",
    "    sectioned_df = pd.read_csv(save_sectioned_df_to_file, encoding=\"utf-8\", sep=\"|\")\n",
    "\n",
    "print(f'Total number of sections: {len(sectioned_df)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_summary_with_embeddings = \"./tmp/summary_gdpr_with_embedding.parquet\"\n",
    "article_questions_with_embeddings = \"./tmp/questions_gdpr_with_embedding.parquet\"\n",
    "article_headings_index_file = \"./tmp/headings.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary data contains 64 lines of text\n",
      "Questions data contains 64 lines of text\n",
      "There are a total number of 99 sections to index\n",
      "You have created 64.65 percent of your text index\n"
     ]
    }
   ],
   "source": [
    "df_summary = None\n",
    "if os.path.exists(article_summary_with_embeddings):\n",
    "    df_summary = pd.read_parquet(article_summary_with_embeddings, engine='pyarrow')\n",
    "    print(f\"Summary data contains {len(df_summary)} lines of text\")\n",
    "    missing = len(df_summary[df_summary[\"text\"] == \"\"])\n",
    "    if missing > 0:\n",
    "        print(f\" -- of which there are {missing} lines that do not contain index text (e.g. sections with only definitions or indexes)\")\n",
    "else:\n",
    "    print(\"Creating a new summary DataFrame\")\n",
    "    df_summary = pd.DataFrame([], columns = [\"text\", \"article\"])\n",
    "\n",
    "\n",
    "df_questions = None\n",
    "if os.path.exists(article_questions_with_embeddings):\n",
    "    df_questions = pd.read_parquet(article_questions_with_embeddings, engine='pyarrow')\n",
    "    print(f\"Questions data contains {len(df_questions)} lines of text\")    \n",
    "    missing = len(df_questions[df_questions[\"text\"] == \"\"])\n",
    "    if missing > 0:\n",
    "        print(f\" -- of which there are {missing} lines that do not contain index text (e.g. sections with only definitions or indexes)\")\n",
    "else:\n",
    "    print(\"Creating a new questions DataFrame\")\n",
    "    df_questions = pd.DataFrame([], columns = [\"text\", \"article\"])\n",
    "\n",
    "index = None\n",
    "if len(df_summary) != len(df_questions):\n",
    "    print(\"The summary and the questions DataFrames do not have the same length\")\n",
    "else:\n",
    "    index = len(df_summary)\n",
    "    p = (index / len(sectioned_df)) * 100\n",
    "    print(f'There are a total number of {len(sectioned_df)} sections to index')\n",
    "    print(f\"You have created {p:.2f} percent of your text index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "Article 99 Entry into force and application\n",
      "    1. This Regulation shall enter into force on the twentieth day following that of its publication in the Official Journal of the European Union.\n",
      "    2. It shall apply from 25 May 2018.\n",
      "\n",
      "##############\n",
      "df_summary.loc[index, \"article\"] = \"99\"\n",
      "df_summary.loc[index, \"text\"] = \"This regulation became effective 20 days after its publication in the Official Journal of the European Union and has been applicable since 25 May 2018.\"\n",
      "\n",
      "df_questions.loc[index, \"article\"] = \"99\"\n",
      "df_questions.loc[index, \"text\"] = \"When did GDPR come into effect?|What is the timeline for GDPR becoming applicable?\"\n"
     ]
    }
   ],
   "source": [
    "#model = \"gpt-3.5-turbo\"\n",
    "#model=\"gpt-4\"\n",
    "model = \"gpt-4-0125-preview\"\n",
    "\n",
    "reg_text = sectioned_df.loc[index]['text']\n",
    "print(\"##############\")\n",
    "print(reg_text)\n",
    "print(\"##############\")\n",
    "\n",
    "model_summary, model_questions = get_summary_and_questions_for(openai_client = openai_client, text = reg_text, model = model)\n",
    "\n",
    "#format output\n",
    "article = sectioned_df.loc[index]['article']\n",
    "print(f'df_summary.loc[index, \"article\"] = \"{article}\"')\n",
    "print(f'df_summary.loc[index, \"text\"] = \"{model_summary}\"')\n",
    "print()\n",
    "print(f'df_questions.loc[index, \"article\"] = \"{article}\"')\n",
    "print(f'df_questions.loc[index, \"text\"] = \"{model_questions}\"')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done!\n"
     ]
    }
   ],
   "source": [
    "df_summary.loc[index, \"article\"] = \"99\"\n",
    "df_summary.loc[index, \"text\"] = \"This regulation became effective 20 days after its publication in the Official Journal of the European Union and has been applicable since 25 May 2018.\"\n",
    "\n",
    "df_questions.loc[index, \"article\"] = \"99\"\n",
    "df_questions.loc[index, \"text\"] = \"When did GDPR come into effect?|What is the timeline for GDPR becoming applicable?\"\n",
    "\n",
    "\n",
    "\n",
    "index = index + 1\n",
    "if index == len(sectioned_df):\n",
    "    print(\"All done!\")\n",
    "else:\n",
    "    next_section = sectioned_df.iloc[index][\"article\"]\n",
    "    assert len(sectioned_df[sectioned_df[\"article\"] == next_section]) == 1, \"Huston, we have a problem\"\n",
    "    print(f'Next section is {next_section} which is on line {index}')\n",
    "    p = ((index) / len(sectioned_df)) * 100\n",
    "    print(f\"You have completed {p:.2f} percent of your work\")\n",
    "    reg_text = sectioned_df.loc[index]['text']\n",
    "    print(\"Next section\")\n",
    "    print(\"##############\")\n",
    "    print(reg_text)\n",
    "    print(\"##############\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = index + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes there are errors in the previous code block. We need to be careful when saving over any work we have already done so the \n",
    "# save step is a manual one which needs to be run regularly but without overwriting good data with bad data\n",
    "df_summary.to_parquet(article_summary_with_embeddings, engine='pyarrow')\n",
    "df_questions.to_parquet(article_questions_with_embeddings, engine='pyarrow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This Regulation establishes rules for the prot...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This Regulation applies to the processing of p...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Regulation applies to the processing of pe...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Personal data must be processed lawfully, fair...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Processing of personal data is only lawful if ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>This Regulation won't add extra obligations on...</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>International agreements made by Member States...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>The European Commission is required to evaluat...</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>The Commission may propose changes to other EU...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>This regulation became effective 20 days after...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text article\n",
       "0   This Regulation establishes rules for the prot...       1\n",
       "1   This Regulation applies to the processing of p...       2\n",
       "2   The Regulation applies to the processing of pe...       3\n",
       "4   Personal data must be processed lawfully, fair...       5\n",
       "5   Processing of personal data is only lawful if ...       6\n",
       "..                                                ...     ...\n",
       "94  This Regulation won't add extra obligations on...      95\n",
       "95  International agreements made by Member States...      96\n",
       "96  The European Commission is required to evaluat...      97\n",
       "97  The Commission may propose changes to other EU...      98\n",
       "98  This regulation became effective 20 days after...      99\n",
       "\n",
       "[98 rows x 2 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has_duplicates : False\n",
      "missing_numbers : {4}\n"
     ]
    }
   ],
   "source": [
    "articles = df_summary['article'].to_list()\n",
    "articles_int = [int(article) for article in articles]\n",
    "has_duplicates = len(articles) != len(set(articles))\n",
    "print(f'has_duplicates : {has_duplicates}')\n",
    "missing_numbers = set(range(1, 71)) - set(articles_int)\n",
    "print(f'missing_numbers : {missing_numbers}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the index file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "550\n"
     ]
    }
   ],
   "source": [
    "# article_summary_with_embeddings \n",
    "# article_questions_with_embeddings\n",
    "\n",
    "df_index = pd.read_parquet(article_questions_with_embeddings, engine='pyarrow')\n",
    "df_index = df_index[df_index[\"text\"] != \"\"] # remove rows that have 'text' == \"\"\n",
    "print(len(df_index))\n",
    "# the 'text' column for the questions may contain multiple questions separated by a \"|\". The next line expands these rows\n",
    "# so the value in 'text' only contains one question\n",
    "df_index = df_index.drop(\"text\", axis=1).join(df_index[\"text\"].str.split(\"|\", expand=True).stack().reset_index(level=1, drop=True).rename(\"text\"))\n",
    "df_index.reset_index(drop=True, inplace=True)\n",
    "print(len(df_index))\n",
    "df_index[\"source\"] = \"question\"\n",
    "\n",
    "df_tmp = pd.read_parquet(article_summary_with_embeddings , engine='pyarrow')\n",
    "df_tmp[\"source\"] = \"summary\"\n",
    "\n",
    "df_index = pd.concat([df_index, df_tmp], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647\n",
      "647\n"
     ]
    }
   ],
   "source": [
    "print(len(df_index))\n",
    "df_index = df_index[df_index[\"text\"]!= \"\"]\n",
    "df_index = df_index[df_index[\"text\"].notna()] # Remove any NaN's\n",
    "df_index.reset_index(drop=True, inplace=True)\n",
    "print(len(df_index))\n",
    "\n",
    "index_file = './inputs/index_gdpr.parquet'\n",
    "df_index.to_parquet(index_file, engine = 'pyarrow')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regulations_rag.standard_regulation_index import load_parquet_data, save_parquet_data\n",
    "import os\n",
    "key = os.getenv('encryption_key_gdpr')\n",
    "#dfn_index = load_parquet_data(\"../inputs/definitions_gdpr.parquet\")\n",
    "index_df = load_parquet_data(\"../inputs/index/gdpr.parquet\", key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfns = index_df[index_df['source'] == \"definitions\"]\n",
    "#index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_quoted_text(s):\n",
    "    matches = re.findall(r\"'([^']*)'\", s)\n",
    "    return matches[0] if matches else \"\"\n",
    "\n",
    "# Create list using the extracted text\n",
    "what_is_list = [\"What is \" + extract_quoted_text(text) + \"?\" for text in dfns['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "what_is_list = ['What is personal data?',\n",
    " 'What is processing?',\n",
    " 'What is restriction of processing?',\n",
    " 'What is profiling?',\n",
    " 'What is pseudonymisation?',\n",
    " 'What is a filing system?',\n",
    " 'What is a controller?',\n",
    " 'What is a processor?',\n",
    " 'What is a recipient?',\n",
    " 'What is a third party?',\n",
    " 'What is consent?',\n",
    " 'What is a personal data breach?',\n",
    " 'What is genetic data?',\n",
    " 'What is biometric data?',\n",
    " 'What is data concerning health?',\n",
    " 'What is a main establishment?',\n",
    " 'What is a representative?',\n",
    " 'What is an enterprise?',\n",
    " 'What is a group of undertakings?',\n",
    " 'What are binding corporate rules?',\n",
    " 'What is supervisory authority?',\n",
    " 'What is supervisory authority concerned?',\n",
    " 'What is cross-border processing?',\n",
    " 'What is relevant and reasoned objection?',\n",
    " 'What is information society service?',\n",
    " 'What is international organisation?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'personal data' means any information relating to an identified or identifiable natural person ('data subject'); an identifiable natural person is one who can be identified, directly or indirectly, in particular by reference to an identifier such as a name, an identification number, location data, an online identifier or to one or more factors specific to the physical, physiological, genetic, mental, economic, cultural or social identity of that natural person;\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_change = dfns.iloc[0][\"text\"]\n",
    "text_to_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m dfns\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m---> 13\u001b[0m     update_text_in_index(openai_client \u001b[38;5;241m=\u001b[39m openai_client, index_df \u001b[38;5;241m=\u001b[39m index_df, text_to_change \u001b[38;5;241m=\u001b[39m \u001b[43mdfns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcounter\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m], changed_text \u001b[38;5;241m=\u001b[39m what_is_list[counter], embedding_model \u001b[38;5;241m=\u001b[39m model, embedding_dimensions \u001b[38;5;241m=\u001b[39m dimensions)\n\u001b[0;32m     14\u001b[0m     counter \u001b[38;5;241m=\u001b[39m counter \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32me:\\Code\\chat\\gdpr\\env\\lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1189\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m   1190\u001b[0m maybe_callable \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[1;32m-> 1191\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32me:\\Code\\chat\\gdpr\\env\\lib\\site-packages\\pandas\\core\\indexing.py:1752\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index by location index with a non-integer key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1751\u001b[0m \u001b[39m# validate the location\u001b[39;00m\n\u001b[1;32m-> 1752\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_integer(key, axis)\n\u001b[0;32m   1754\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_ixs(key, axis\u001b[39m=\u001b[39maxis)\n",
      "File \u001b[1;32me:\\Code\\chat\\gdpr\\env\\lib\\site-packages\\pandas\\core\\indexing.py:1685\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1683\u001b[0m len_axis \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis))\n\u001b[0;32m   1684\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m len_axis \u001b[39mor\u001b[39;00m key \u001b[39m<\u001b[39m \u001b[39m-\u001b[39mlen_axis:\n\u001b[1;32m-> 1685\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msingle positional indexer is out-of-bounds\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "openai_client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"),)\n",
    "\n",
    "import sys\n",
    "sys.path.append('E:/Code/chat/gdpr')\n",
    "\n",
    "from src.index_tools import update_text_in_index\n",
    "\n",
    "model = \"text-embedding-3-large\"\n",
    "dimensions = 1024\n",
    "counter = 1\n",
    "for index, row in dfns.iterrows():\n",
    "    update_text_in_index(openai_client = openai_client, index_df = index_df, text_to_change = dfns.iloc[counter][\"text\"], changed_text = what_is_list[counter], embedding_model = model, embedding_dimensions = dimensions)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "      <th>source</th>\n",
       "      <th>section_reference</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What is supervisory authority?</td>\n",
       "      <td>[-0.02389775589108467, -0.02977169118821621, -...</td>\n",
       "      <td>definitions</td>\n",
       "      <td>4(21)</td>\n",
       "      <td>GDPR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>What is supervisory authority concerned?</td>\n",
       "      <td>[-0.016888560727238655, 0.003025628859177232, ...</td>\n",
       "      <td>definitions</td>\n",
       "      <td>4(22)</td>\n",
       "      <td>GDPR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>What is cross-border processing?</td>\n",
       "      <td>[-0.03551863506436348, -3.7787705764458224e-07...</td>\n",
       "      <td>definitions</td>\n",
       "      <td>4(23)</td>\n",
       "      <td>GDPR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What is relevant and reasoned objection?</td>\n",
       "      <td>[-0.01737261191010475, -0.005801921710371971, ...</td>\n",
       "      <td>definitions</td>\n",
       "      <td>4(24)</td>\n",
       "      <td>GDPR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>What is information society service?</td>\n",
       "      <td>[-0.04533061757683754, 0.06807615607976913, -0...</td>\n",
       "      <td>definitions</td>\n",
       "      <td>4(25)</td>\n",
       "      <td>GDPR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>What is international organisation?</td>\n",
       "      <td>[-0.05958525463938713, -0.022743836045265198, ...</td>\n",
       "      <td>definitions</td>\n",
       "      <td>4(26)</td>\n",
       "      <td>GDPR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>What are the main purposes of GDPR?</td>\n",
       "      <td>[-0.06360988318920135, -0.05781147629022598, -...</td>\n",
       "      <td>question</td>\n",
       "      <td>1</td>\n",
       "      <td>GDPR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>What rights and freedoms does GDPR protect for...</td>\n",
       "      <td>[-0.07677329331636429, -0.0514022633433342, -0...</td>\n",
       "      <td>question</td>\n",
       "      <td>1</td>\n",
       "      <td>GDPR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Is the movement of personal data allowed withi...</td>\n",
       "      <td>[-0.06736818701028824, -0.009348609484732151, ...</td>\n",
       "      <td>question</td>\n",
       "      <td>1</td>\n",
       "      <td>GDPR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>What does GDPR apply to?</td>\n",
       "      <td>[-0.08824595808982849, 0.0009544518543407321, ...</td>\n",
       "      <td>question</td>\n",
       "      <td>2</td>\n",
       "      <td>GDPR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "20                     What is supervisory authority?   \n",
       "21           What is supervisory authority concerned?   \n",
       "22                   What is cross-border processing?   \n",
       "23           What is relevant and reasoned objection?   \n",
       "24               What is information society service?   \n",
       "25                What is international organisation?   \n",
       "26                What are the main purposes of GDPR?   \n",
       "27  What rights and freedoms does GDPR protect for...   \n",
       "28  Is the movement of personal data allowed withi...   \n",
       "29                           What does GDPR apply to?   \n",
       "\n",
       "                                            embedding       source  \\\n",
       "20  [-0.02389775589108467, -0.02977169118821621, -...  definitions   \n",
       "21  [-0.016888560727238655, 0.003025628859177232, ...  definitions   \n",
       "22  [-0.03551863506436348, -3.7787705764458224e-07...  definitions   \n",
       "23  [-0.01737261191010475, -0.005801921710371971, ...  definitions   \n",
       "24  [-0.04533061757683754, 0.06807615607976913, -0...  definitions   \n",
       "25  [-0.05958525463938713, -0.022743836045265198, ...  definitions   \n",
       "26  [-0.06360988318920135, -0.05781147629022598, -...     question   \n",
       "27  [-0.07677329331636429, -0.0514022633433342, -0...     question   \n",
       "28  [-0.06736818701028824, -0.009348609484732151, ...     question   \n",
       "29  [-0.08824595808982849, 0.0009544518543407321, ...     question   \n",
       "\n",
       "   section_reference document  \n",
       "20             4(21)     GDPR  \n",
       "21             4(22)     GDPR  \n",
       "22             4(23)     GDPR  \n",
       "23             4(24)     GDPR  \n",
       "24             4(25)     GDPR  \n",
       "25             4(26)     GDPR  \n",
       "26                 1     GDPR  \n",
       "27                 1     GDPR  \n",
       "28                 1     GDPR  \n",
       "29                 2     GDPR  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_df[20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_parquet_data(index_df, \"../inputs/index/gdpr.parquet\", key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.loc[index['document'] == 'gdpr', 'document'] = 'GDPR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_parquet_data(index, \"../inputs/index/gdpr.parquet\", key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn_index['section_reference'] = dfn_index.index.to_series().apply(lambda x: f\"4({x+1})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn_index.rename(columns={'definition': 'text'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn_index.drop('term', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn_index['source'] = 'definitions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn_index.to_parquet(\"../inputs/definitions_gdpr.parquet\", engine = \"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "combined = pd.concat([dfn_index, index], ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined[\"document\"] = \"gdpr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdpr_index_file = \"../inputs/gdpr.index\"\n",
    "save_parquet_data(combined, gdpr_index_file, key)\n",
    "#combined.to_parquet(gdpr_index_file, engine = 'pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20591bc9273590117cdd0f52559c248ef39f0181da66e3521068e03aa47654cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
